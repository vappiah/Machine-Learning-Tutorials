{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vappiah/Machine-Learning-Tutorials/blob/main/notebooks/projects/Neural_Networks_for_Cancer_Prediction_Episode_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b05c990e",
      "metadata": {
        "id": "b05c990e"
      },
      "source": [
        "# Neural Network for Cancer Prediction\n",
        "The data used for this tutorial is an RNA-seq gene expression data for different cancer types. The rows represent cancer samples and the columns represent gene count values. The last column contains the cancer categories.\n",
        "\n",
        "The original data can found here: https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7202fe",
      "metadata": {
        "id": "5d7202fe"
      },
      "source": [
        "## Required Libraries\n",
        " - numpy\n",
        " - matplotlib\n",
        " - pandas\n",
        " - tensorflow\n",
        " - keras\n",
        " - scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91f3dde3",
      "metadata": {
        "id": "91f3dde3"
      },
      "source": [
        "## Import Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0515dec",
      "metadata": {
        "id": "a0515dec"
      },
      "outputs": [],
      "source": [
        "#data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#classification\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b45976a3",
      "metadata": {
        "id": "b45976a3"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a5cb29",
      "metadata": {
        "id": "25a5cb29"
      },
      "outputs": [],
      "source": [
        "\n",
        "#read data directly from a github repository\n",
        "file_url='https://github.com/vappiah/Machine-Learning-Tutorials/raw/main/data/cancer_gene_expression.zip'\n",
        "\n",
        "dataframe=pd.read_csv(file_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e214ad93",
      "metadata": {
        "id": "e214ad93"
      },
      "source": [
        "\n",
        "## Data Exploration & Cleaning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e48d71",
      "metadata": {
        "scrolled": true,
        "id": "18e48d71"
      },
      "outputs": [],
      "source": [
        "#let's check the number of samples and features\n",
        "#note:the last column contain the labels. it is not considered as a feature\n",
        "\n",
        "print(dataframe.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e833043",
      "metadata": {
        "id": "7e833043"
      },
      "outputs": [],
      "source": [
        "#let's check some of the columns (first, second and third columns)\n",
        "print(dataframe.columns[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aee3bf1",
      "metadata": {
        "id": "2aee3bf1"
      },
      "outputs": [],
      "source": [
        "#lets check the name of the last column of this dataframe\n",
        "\n",
        "dataframe.columns[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229679e0",
      "metadata": {
        "id": "229679e0"
      },
      "outputs": [],
      "source": [
        "#check for missing values\n",
        "datanul=dataframe.isnull().sum()\n",
        "g=[i for i in datanul if i>0]\n",
        "\n",
        "print('columns with missing values:%d'%len(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "000af60f",
      "metadata": {
        "id": "000af60f"
      },
      "source": [
        "**GOOD JOB!!!!.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0560c5a",
      "metadata": {
        "scrolled": true,
        "id": "d0560c5a"
      },
      "outputs": [],
      "source": [
        "#let's check how many different cancer types are there in the data\n",
        "#note: in this tutorial the cancer types will be referred to as classes or labels\n",
        "\n",
        "print(dataframe['Cancer_Type'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "046d64c6",
      "metadata": {
        "id": "046d64c6"
      },
      "source": [
        "We can see that there are 5 classes/cancer types. And you can also see the number of samples diagnosed with a cancer type\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a0e165b",
      "metadata": {
        "id": "7a0e165b"
      },
      "source": [
        " \n",
        "## **Data preprocesing** \n",
        "This is done to put the data in an appropriate format before modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13b9f51",
      "metadata": {
        "id": "a13b9f51"
      },
      "outputs": [],
      "source": [
        "#we will now seperate the feature values from the class. we do this because scikit-learn requires that features and class are separated before parsing them to the classifiers.\n",
        "X=dataframe.iloc[:,0:-1]\n",
        "y=dataframe.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264a01cb",
      "metadata": {
        "id": "264a01cb"
      },
      "source": [
        "\\\n",
        "**Encode labels**\n",
        "\n",
        "The labels for this data are categorical and we therefore have to convert them to numeric forms. This is referred to as encoding. Machine learning models usually require input data to be in numeric forms, hence we encoding the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b251f08b",
      "metadata": {
        "id": "b251f08b"
      },
      "outputs": [],
      "source": [
        "#let's encode target labels (y) with values between 0 and n_classes-1.\n",
        "#encoding will be done using the LabelEncoder\n",
        "label_encoder=LabelEncoder()\n",
        "label_encoder.fit(y)\n",
        "y=label_encoder.transform(y)\n",
        "labels=label_encoder.classes_\n",
        "classes=np.unique(y)\n",
        "nclasses=np.unique(y).shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1c8d5e",
      "metadata": {
        "id": "0d1c8d5e"
      },
      "source": [
        "\\\n",
        "**Data Normalization**\\\n",
        "Data normalization is done so that the values are in the same range. This will improve model performance and avoid bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7fc9256",
      "metadata": {
        "id": "b7fc9256"
      },
      "outputs": [],
      "source": [
        "### scale the data between 0-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a06d2f6",
      "metadata": {
        "id": "4a06d2f6"
      },
      "outputs": [],
      "source": [
        "min_max_scaler=MinMaxScaler()\n",
        "X=min_max_scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f68c4f6",
      "metadata": {
        "id": "5f68c4f6"
      },
      "source": [
        "\\\n",
        "**Data Splitting**\\\n",
        "Data is split into three: training, validation and test set\\\n",
        "-training subset is used for training\\\n",
        "-validation subset is used for tuning the model\\\n",
        "-test subset is used to test the model after training and tuning has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bcc2bde",
      "metadata": {
        "id": "7bcc2bde"
      },
      "outputs": [],
      "source": [
        "#split data into training,validation and test sets\n",
        "\n",
        "#split the data into training and test sets\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "#split the training set into two (training and validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a1736a7",
      "metadata": {
        "id": "7a1736a7"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f0ba2c",
      "metadata": {
        "id": "c0f0ba2c"
      },
      "source": [
        "### Build the Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f5060f",
      "metadata": {
        "scrolled": false,
        "id": "f0f5060f"
      },
      "outputs": [],
      "source": [
        "#define model\n",
        "model = Sequential()\n",
        "\n",
        "#hidden layer 1\n",
        "model.add(Dense(40, input_dim=X_train.shape[1], activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "model.add(Dense(20, activation='relu'))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(nclasses, activation='softmax'))\n",
        "\n",
        "#define optimizer and learning rate. We will use Adam optimizer\n",
        "opt_adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=opt_adam, metrics=[keras.metrics.SparseCategoricalAccuracy()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080eb398",
      "metadata": {
        "scrolled": true,
        "id": "080eb398"
      },
      "outputs": [],
      "source": [
        "#fit the model to the training data\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32,epochs=200, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a5b8bc",
      "metadata": {
        "scrolled": false,
        "id": "f5a5b8bc"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "_, accuracy = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e35f6f4a",
      "metadata": {
        "scrolled": true,
        "id": "e35f6f4a"
      },
      "outputs": [],
      "source": [
        "#get the predictions for the first 20 samples in the test set\n",
        "for index,entry in enumerate(predictions[0:20,:]):\n",
        "    print('predicted:%d ,actual:%d'%(np.argmax(entry),y_test[index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ed706e",
      "metadata": {
        "id": "b3ed706e"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.title('model performance')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ddadca",
      "metadata": {
        "id": "e0ddadca"
      },
      "outputs": [],
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Neural Networks for Cancer Prediction -Episode-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}